## Comparisons
|Item to Compare  | Select AI NL2SQL |Vector Search Custom Development | Select AI RAG | Generative AI Agents |
|--- |--- |--- |--- |--- |
|Use Case|Query structured data using a select statement without having to know SQL.|Pose questions and request tasks in a conversational format on unstructured data/documents that have have vector stores.  Queries will return a response that considers the semantics of the prompt, previous related prompts and responses, and document content (meaning and context).|Pose questions and request tasks in a conversational format on unstructured data/documents that have have vector stores.  Queries will return a response that considers the semantics of the prompt, previous related prompts and responses, and document content (meaning and context).|Pose questions and request tasks in a conversational format on unstructured data/documents that have have vector stores.  Queries will return a response that considers the semantics of the prompt, previous related prompts and responses, and document content (meaning and context).|
|Data Sources|Any relational data.|Text or pdf data in the database (optionally loaded from Object Storage).|Text files in Object Storage.|Vector data in the Oracle Database, Object Storage Files (text and pdf only), and OCI OpenSearch|
|Design Approach|A profile is used to specify an AI provider and a schema or table/view to search on.  Then specify ‘select ai’ in your sql query and issue a natural language query.  For each query the table definitions are sent to the AI Provider, which then creates and returns a SQL query , and (optionally) executes it.|Data is loaded (text or pdf documents) into the database, text extracted (from pdf if applicable), and chunked.  Vectors are then created from the text chunks.  A PL/SQL function (or procedure for batch processing) is required to 1 – pass the prompt (question or task), 2 – convert the question into a vector, 3 – perform a query to compare the prompt vector with all other vectors in the source and return top n ranked chunks, 4 – Send the chunks to the AI provider, together with previous related prompts, and 5 – return the response.  The function can be exposed as a REST endpoint for use in applications.|The load process is similar to custom development but automates the end to end processing using a pipeline.  You need a profile and a vector index (created as part of the AI RAG configuration, but NOT created separately as a vector index outside AI RAG).  When the vector index is created a pipeline is created and executed that takes the text files in Object Storage, loads, chunks, and creates vectors on the chunks.  Users can then issue a ‘select ai’...ask whatever you want of the data and the data is searched, chunks sent to the model, and a response is returned. Th process also allows for scheduled updates to the document store.|Create a knowledge base and then an agent that specifies one or more knowledge bases and an endpoint. Then create a PL/SQL function to accept a prompt, create a vector on the prompt, and pass it to the end point. |
|Supported OCI models|||||
|Credentials Required|Provider credential|Provider Credential, OCI Vector Credential|OCI Credential for Object Storage, Provider Credential.  If the Provider is OCI then only one credential is required.||
|PL/SQL Packages Used|dbms\_cloud\_ai.generate|dbms\_cloud, dbms\_vector, dbms\_vector_chain|dbms\_cloud\_ai|n/a|
|Comments|Not every provider model generates useful SQL.  At the moment OpenAI performs best with others somewhat poorer.  The models rely entirely on the table/view/synonym table and column names, and database column comments (if any).  IE. existing table and column names for most enterprise applications are not useful.|Development wise this approach requires more code and effort than Select AI RAG, but using previously developed function template only minor code changes are required to customize for a given implementation.  The function template also includes managing conversations and maintaining prompt/response history.  Beware of lengthy conversations that will consume and possibly exceed token limits.  |This approach is extremely easy to set up, but currently only supports text files at this time.  Further, since the entire process is automated it must follow the flow described above.  That is, you cannot arbitrarily use existing text data in the database (eg varchar/clob).  Further, some of the vector and chunk settings are not exposed.|Currently ADB knowledge sources must co-exist in the same region as the AI service (Chicago).  The ADB instance must also be deployed on a private subnet, requiring an ACL for Data Actions to access the ADB instance.  |


